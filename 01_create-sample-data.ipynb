{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.make_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Data\n",
    "> This module creates batches of random generated orders and saves that to parquet files using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "import uuid\n",
    "import hashlib\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hopeit.app.context import EventContext\n",
    "from hopeit.app.events import Spawn, SHUFFLE\n",
    "from hopeit.app.api import event_api\n",
    "from hopeit.app.logger import app_logger\n",
    "\n",
    "from fraud_poc.jobs import get_client_async, MakeSampleDataJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__steps__ = ['submit_job', SHUFFLE, 'make_batches']\n",
    "\n",
    "__api__ = event_api(\n",
    "    summary=\"Data: Make sample data\",\n",
    "    query_args=[\n",
    "        (\"num_batches\", int, \"Number of batches/files to make\"),\n",
    "        (\"batch_size\", int, \"Number of rows per batch\"),\n",
    "        (\"batch_span_days\", int, \"Number of time span in days for order_date in batch\"),\n",
    "        (\"num_customers\", int, \"Number of customers to generate\"),\n",
    "        (\"num_emails\", int, \"Number of emails to generate\"),\n",
    "        (\"num_ips\", int, \"Number of IP addresses to generate\")\n",
    "    ],\n",
    "    responses={\n",
    "        200: (MakeSampleDataJob, \"Job submitted\")\n",
    "    }\n",
    ")\n",
    "\n",
    "logger = app_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OrderRandomSource:\n",
    "    @staticmethod\n",
    "    def new_uuid(): return str(uuid.uuid4())\n",
    "    \n",
    "    @staticmethod\n",
    "    def new_hash(): return hashlib.sha1(str(uuid.uuid4()).encode()).hexdigest()\n",
    "\n",
    "    def __init__(self, days_ago: int, days_span: int,\n",
    "                 customer_ids: list, emails: list, email_to_customer: list, ips, email_to_ip: list):\n",
    "        self.num_customers = len(customer_ids)\n",
    "        self.num_ips = len(ips)\n",
    "        self.num_emails = len(emails)\n",
    "        self.lat_min, self.lat_max = -20., -10.\n",
    "        self.long_min, self.long_max = -20., -10.\n",
    "        self.to_date = datetime.now(tz=timezone.utc) - timedelta(days=days_ago)\n",
    "        self.to_date_epoch = int(self.to_date.timestamp())\n",
    "        self.from_date = self.to_date - timedelta(days=days_span)\n",
    "        self.from_date_epoch = int(self.from_date.timestamp())\n",
    "        self.customer_ids = customer_ids\n",
    "        self.emails = emails\n",
    "        self.email_to_customer = email_to_customer\n",
    "        self.ips = ips\n",
    "        self.email_to_ip = email_to_ip\n",
    "        \n",
    "    def random_order(self):\n",
    "        email_idx = random.randint(0, self.num_emails-1)\n",
    "        email = self.emails[email_idx]\n",
    "        customer_id = self.email_to_customer[email_idx]\n",
    "        ip_addr = self.email_to_ip[email_idx] if random.random() > 0.1 else self.new_hash()\n",
    "        date_epoch = random.randint(self.from_date_epoch, self.to_date_epoch)\n",
    "        date = datetime.fromtimestamp(date_epoch, tz=timezone.utc)\n",
    "        lat = self.lat_min + random.random() * (self.lat_max - self.lat_min)\n",
    "        long = self.long_min + random.random() * (self.long_max - self.long_min)\n",
    "        amount = random.random() * 1000.\n",
    "        return {\n",
    "            'order_id': self.new_uuid(),\n",
    "            'order_date': date,\n",
    "            'customer_id': customer_id,\n",
    "            'email': email,\n",
    "            'ip_addr': ip_addr,\n",
    "            'location_lat': lat,\n",
    "            'location_long': long,\n",
    "            'order_amount': amount\n",
    "        }\n",
    "\n",
    "    def _generate_orders(self, n: int):\n",
    "        for _ in range(n):\n",
    "            yield self.random_order()\n",
    "\n",
    "    def __call__(self, n: int):\n",
    "        return pd.DataFrame(self._generate_orders(n))\n",
    "\n",
    "    @staticmethod\n",
    "    def meta(): \n",
    "        return {'order_id': object, \n",
    "               'order_date': 'datetime64[ns, UTC]', \n",
    "               'customer_id': object, \n",
    "               'email': object, \n",
    "               'ip_addr': object, \n",
    "               'location_lat': float, \n",
    "               'location_long': float, \n",
    "               'order_amount': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_batch(path: str, i: int, size: int, days_span: int,\n",
    "               customer_ids: list, emails: list, email_to_customer: list, ips, email_to_ip: list):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    days_ago = i * days_span\n",
    "    random_orders = OrderRandomSource(days_ago=days_ago, days_span=days_span,\n",
    "                                      customer_ids=customer_ids, emails=emails, email_to_customer=email_to_customer, \n",
    "                                      ips=ips, email_to_ip=email_to_ip)\n",
    "    df = random_orders(size) #, meta=random_orders.meta())\n",
    "    file_name = f'{path}/batch{i:02}.parquet'\n",
    "    df.to_parquet(file_name, engine='fastparquet', compression='LZ4')\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "async def submit_job(payload: None, context: EventContext, \n",
    "                     num_batches: int = 12, batch_size: int = 100000, batch_span_days: int = 30,\n",
    "                     num_customers: int = 10000, num_emails: int = 10000, num_ips: int = 10000) -> MakeSampleDataJob:\n",
    "    path = context.env['data']['raw']\n",
    "    return MakeSampleDataJob(path, int(num_batches), int(batch_size), int(batch_span_days),\n",
    "                            int(num_customers), int(num_emails), int(num_ips))\n",
    "\n",
    "async def make_batches(job: MakeSampleDataJob, context: EventContext) -> MakeSampleDataJob:\n",
    "    logger.info(context, f\"Executing: {job}...\")\n",
    "    client = await get_client_async(context)\n",
    "    logger.info(context, f\"Dask: {client}\")\n",
    "    try:\n",
    "        batches = []\n",
    "        customer_ids = [OrderRandomSource.new_uuid() for i in range(job.num_customers)]\n",
    "        emails = [OrderRandomSource.new_hash() for i in range(job.num_emails)]\n",
    "        email_to_customer = [customer_ids[random.randint(0, job.num_customers-1)] for i in range(job.num_emails)]\n",
    "        ips = [OrderRandomSource.new_hash() for i in range(job.num_ips)]\n",
    "        email_to_ip = [ips[random.randint(0, job.num_ips-1)] for i in range(job.num_emails)] \n",
    "\n",
    "        for i in range(job.num_batches):\n",
    "            logger.info(context, f\"Submitting batch {i}...\")\n",
    "            batches.append(\n",
    "                client.submit(_make_batch, job.path, i, job.batch_size, job.batch_span_days,\n",
    "                             customer_ids, emails, email_to_customer, ips, email_to_ip)\n",
    "            )\n",
    "\n",
    "        for batch in batches:\n",
    "            res = await batch\n",
    "            logger.info(context, f\"Done batch: {res}.\")\n",
    "        #dfs = await client.gather(*batches)\n",
    "        return job\n",
    "    except Exception as e:\n",
    "        logger.error(context, e)\n",
    "        return None\n",
    "    finally:\n",
    "        await client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nbdev_build_lib\n"
     ]
    }
   ],
   "source": [
    "! nbdev_build_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 20:24:07,412 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Executing: MakeSampleDataJob(path='./data/raw', num_batches=2, batch_size=100, batch_span_days=10, num_customers=100, num_emails=100, num_ips=100)... | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n",
      "2021-05-18 20:24:08,219 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Dask: <Client: 'tcp://127.0.0.1:58174' processes=4 threads=8, memory=16.00 GiB> | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n",
      "2021-05-18 20:24:08,224 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Submitting batch 0... | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n",
      "2021-05-18 20:24:08,226 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Submitting batch 1... | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n",
      "2021-05-18 20:24:08,796 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Done batch: ./data/raw/batch00.parquet. | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n",
      "2021-05-18 20:24:08,811 | INFO | fraud-poc training data.make-sample-data ALT00617 74682 | Done batch: ./data/raw/batch01.parquet. | track.operation_id=test_operation_id | track.request_id=test_request_id | track.request_ts=2021-05-18T20:24:07.412401+00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MakeSampleDataJob(path='./data/raw', num_batches=2, batch_size=100, batch_span_days=10, num_customers=100, num_emails=100, num_ips=100)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hopeit.testing.apps import config, execute_event\n",
    "\n",
    "app_config = config('config/training-pipeline.json')\n",
    "result = await execute_event(app_config, 'data.make-sample-data', None,\n",
    "                            num_batches=2, batch_size=100, batch_span_days=10,\n",
    "                            num_customers=100, num_emails=100, num_ips=100)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>email</th>\n",
       "      <th>ip_addr</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>location_long</th>\n",
       "      <th>order_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a699fab-b8b3-4e19-bbc6-0e970ffba031</td>\n",
       "      <td>2021-05-11 17:35:50+00:00</td>\n",
       "      <td>5132ccfc-ce47-4f4d-bdb2-f8fface2ab5f</td>\n",
       "      <td>bad573204742b126622e6a5c090b3769a33a3308</td>\n",
       "      <td>52d44eb8e3243a1adf9a43b74e0b7629be671277</td>\n",
       "      <td>-10.835709</td>\n",
       "      <td>-19.554605</td>\n",
       "      <td>877.709842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1452029f-f659-4611-9f8c-5a23fd1626cf</td>\n",
       "      <td>2021-05-17 13:24:05+00:00</td>\n",
       "      <td>25817e58-f0f5-4d0a-bc74-6fc00ce9c70d</td>\n",
       "      <td>1ebd4eae5ff22fff30e8dc152d8571a9ba5774bd</td>\n",
       "      <td>449e07ab35d65c5a874740bf8e22d2a4d0fbce7a</td>\n",
       "      <td>-13.531581</td>\n",
       "      <td>-10.881747</td>\n",
       "      <td>235.479339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31510480-2267-430a-a638-2cd42cfc60f4</td>\n",
       "      <td>2021-05-11 23:12:56+00:00</td>\n",
       "      <td>c6eb3cd2-93bc-413f-a0e9-61c71ab0d224</td>\n",
       "      <td>5402e6915b106c264bd2bd7d7194e45d6de83091</td>\n",
       "      <td>29854c437e114323911562c081daa967fc2418a4</td>\n",
       "      <td>-11.012069</td>\n",
       "      <td>-10.141314</td>\n",
       "      <td>68.890731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9f461fd9-2ad1-4c61-b600-24af355d8e63</td>\n",
       "      <td>2021-05-14 00:25:21+00:00</td>\n",
       "      <td>8a6a7275-c331-48aa-baa6-970014d04963</td>\n",
       "      <td>da80f9f0a66ba22fc910f9fb6fc7bbbd3d79fab3</td>\n",
       "      <td>14e11fef153a52f328d803fc07b48905c8a8c31f</td>\n",
       "      <td>-18.711148</td>\n",
       "      <td>-12.039022</td>\n",
       "      <td>444.247712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9cc8c9aa-e342-4e7a-8269-4ebb7bc0d208</td>\n",
       "      <td>2021-05-15 04:11:54+00:00</td>\n",
       "      <td>09da86be-63c3-4265-a799-8fe5efaf270c</td>\n",
       "      <td>79cdeec4056ed0714127c4c255d9dafa334ee2a7</td>\n",
       "      <td>ee714f6b18d2b01e2d632f1299d8cb7618099070</td>\n",
       "      <td>-16.110130</td>\n",
       "      <td>-13.836294</td>\n",
       "      <td>955.929156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               order_id                order_date  \\\n",
       "0  5a699fab-b8b3-4e19-bbc6-0e970ffba031 2021-05-11 17:35:50+00:00   \n",
       "1  1452029f-f659-4611-9f8c-5a23fd1626cf 2021-05-17 13:24:05+00:00   \n",
       "2  31510480-2267-430a-a638-2cd42cfc60f4 2021-05-11 23:12:56+00:00   \n",
       "3  9f461fd9-2ad1-4c61-b600-24af355d8e63 2021-05-14 00:25:21+00:00   \n",
       "4  9cc8c9aa-e342-4e7a-8269-4ebb7bc0d208 2021-05-15 04:11:54+00:00   \n",
       "\n",
       "                            customer_id  \\\n",
       "0  5132ccfc-ce47-4f4d-bdb2-f8fface2ab5f   \n",
       "1  25817e58-f0f5-4d0a-bc74-6fc00ce9c70d   \n",
       "2  c6eb3cd2-93bc-413f-a0e9-61c71ab0d224   \n",
       "3  8a6a7275-c331-48aa-baa6-970014d04963   \n",
       "4  09da86be-63c3-4265-a799-8fe5efaf270c   \n",
       "\n",
       "                                      email  \\\n",
       "0  bad573204742b126622e6a5c090b3769a33a3308   \n",
       "1  1ebd4eae5ff22fff30e8dc152d8571a9ba5774bd   \n",
       "2  5402e6915b106c264bd2bd7d7194e45d6de83091   \n",
       "3  da80f9f0a66ba22fc910f9fb6fc7bbbd3d79fab3   \n",
       "4  79cdeec4056ed0714127c4c255d9dafa334ee2a7   \n",
       "\n",
       "                                    ip_addr  location_lat  location_long  \\\n",
       "0  52d44eb8e3243a1adf9a43b74e0b7629be671277    -10.835709     -19.554605   \n",
       "1  449e07ab35d65c5a874740bf8e22d2a4d0fbce7a    -13.531581     -10.881747   \n",
       "2  29854c437e114323911562c081daa967fc2418a4    -11.012069     -10.141314   \n",
       "3  14e11fef153a52f328d803fc07b48905c8a8c31f    -18.711148     -12.039022   \n",
       "4  ee714f6b18d2b01e2d632f1299d8cb7618099070    -16.110130     -13.836294   \n",
       "\n",
       "   order_amount  \n",
       "0    877.709842  \n",
       "1    235.479339  \n",
       "2     68.890731  \n",
       "3    444.247712  \n",
       "4    955.929156  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "dd.read_parquet(result.path).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
