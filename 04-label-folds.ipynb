{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Generator\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "import uuid\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.distributed import Client\n",
    "from pathlib import Path\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41121</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>33.54 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41121' processes=4 threads=12, memory=33.54 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(df, count_cols, stat_cols, by):\n",
    "    counts = count_distinct_values(df, count_cols, by)\n",
    "    stats = num_stats(df, stat_cols, by)\n",
    "    right = counts.merge(stats)\n",
    "    df = df.merge(right,\n",
    "                  left_on=[df.index, 'order_id'], \n",
    "                  right_on=[by, 'order_id'],\n",
    "                  suffixes=('', f's_by_{by}'))\n",
    "    return df\n",
    "        \n",
    "\n",
    "def count_distinct_values(df, cols, by):\n",
    "    results = []\n",
    "    for col in cols:\n",
    "        results.append( \n",
    "            df.groupby([df.index, df.order_date, df.order_id])[col] \\\n",
    "                .apply(list) \\\n",
    "                .sort_index() \\\n",
    "                .groupby(level=0) \\\n",
    "                .apply(np.cumsum) \\\n",
    "                .apply(lambda x: len(set(x))))\n",
    "        \n",
    "    counts = results[0].to_frame()\n",
    "    for col, result in zip(cols[1:], results[1:]):\n",
    "        counts[col] = result\n",
    "\n",
    "    counts = counts.reset_index()[[by, 'order_id', *cols]]\n",
    "    return counts\n",
    "\n",
    "def num_stats(df, cols, by):\n",
    "    results = []\n",
    "    for col in cols:\n",
    "        results.append(df.groupby([df.index, df.order_date, df.order_id])[col] \\\n",
    "                .apply(list) \\\n",
    "                .sort_index() \\\n",
    "                .groupby(level=0) \\\n",
    "                .apply(np.cumsum) \\\n",
    "                .apply(lambda x: (np.mean(x), np.std(x), np.min(x), np.max(x), np.sum(x))))\n",
    "        \n",
    "    stats = results[0].to_frame()\n",
    "    for col, result in zip(cols[1:], results[1:]):\n",
    "        stats[col] = result\n",
    "    \n",
    "    stats = stats.reset_index()[[by, 'order_id', *cols]]\n",
    "    for col in cols:\n",
    "        stats[f'{col}_mean_by_{by}'] = stats[col].apply(lambda x: x[0])\n",
    "        stats[f'{col}_std_by_{by}'] = stats[col].apply(lambda x: x[1])\n",
    "        stats[f'{col}_min_by_{by}'] = stats[col].apply(lambda x: x[2])\n",
    "        stats[f'{col}_max_by_{by}'] = stats[col].apply(lambda x: x[3])\n",
    "        stats[f'{col}_sum_by_{by}'] = stats[col].apply(lambda x: x[4])\n",
    "        stats[col] = stats[col].apply(str)\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/dev/anaconda3/envs/dask/lib/python3.7/site-packages/fastparquet/encoding.py:222: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  Numpy8 = numba.jitclass(spec8)(NumpyIO)\n",
      "/opt/dev/anaconda3/envs/dask/lib/python3.7/site-packages/fastparquet/encoding.py:224: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  Numpy32 = numba.jitclass(spec32)(NumpyIO)\n",
      "/opt/dev/anaconda3/envs/dask/lib/python3.7/site-packages/fastparquet/dataframe.py:5: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import CategoricalIndex, RangeIndex, Index, MultiIndex\n"
     ]
    }
   ],
   "source": [
    "df1 = dd.read_parquet(f'./data/features/customer_id/', engine='fastparquet')\n",
    "df2 = dd.read_parquet(f'./data/features/email/', engine='fastparquet')\n",
    "\n",
    "\n",
    "#df = df.map_partitions(calculate, count_cols=['email', 'ip_addr'], stat_cols=['order_amount'], by='customer_id')\n",
    "#df.to_parquet(f'{data_path}/features/customer_id/')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, left_on='order_id', right_on='order_id', suffixes=('', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "subsample_not_fraud = 0.2\n",
    "df['is_fraud'] = ((df.emails_by_customer_id + df.ip_addrs_by_customer_id) > 12) | \\\n",
    "    ((df.order_amount > 1.1 * df.order_amount_mean_by_email) & (df.emails_by_customer_id > 5))\n",
    "df['is_fraud'] = df['is_fraud'].apply(lambda x: int(x & (random.random() > 0.5)), meta=('is_fraud', int))\n",
    "df['sample'] = df['is_fraud'].apply(lambda x: int((x > 0) | (random.random() > (1.-subsample_not_fraud))), meta=('sample', int))\n",
    "df['fold'] = df['is_fraud'].apply(lambda x: random.randint(0, num_folds), meta=('fold', int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[df['sample'] > 0]\n",
    "df_sample = df_sample.set_index('fold')\n",
    "df_sample.to_parquet('./data/labeled/sampled/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
