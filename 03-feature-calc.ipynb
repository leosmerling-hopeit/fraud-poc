{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.feature_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_jobs.ipynb.\n",
      "Converted 01-create-sample-data.ipynb.\n",
      "Converted 02-preprocess.ipynb.\n",
      "Converted 03-feature-calc.ipynb.\n",
      "Converted 04-label-folds.ipynb.\n",
      "Converted 05-training.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "from hopeit.app.context import EventContext\n",
    "from hopeit.app.events import Spawn, SHUFFLE\n",
    "from hopeit.app.api import event_api\n",
    "from hopeit.app.logger import app_logger\n",
    "\n",
    "from fraud_poc.jobs import get_client, FeatureCalcJob, PreprocessingJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__steps__ = ['run']\n",
    "\n",
    "logger = app_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate(df, count_cols, stat_cols, by):\n",
    "    counts = count_distinct_values(df, count_cols, by)\n",
    "    stats = num_stats(df, stat_cols, by)\n",
    "    right = counts.merge(stats)\n",
    "    df = df.merge(right,\n",
    "                  left_on=[df.index, 'order_id'], \n",
    "                  right_on=[by, 'order_id'],\n",
    "                  suffixes=('', f's_by_{by}'))\n",
    "    return df\n",
    "        \n",
    "\n",
    "def count_distinct_values(df, cols, by):\n",
    "    results = []\n",
    "    for col in cols:\n",
    "        results.append( \n",
    "            df.groupby([df.index, df.order_date, df.order_id])[col] \\\n",
    "                .apply(list) \\\n",
    "                .sort_index() \\\n",
    "                .groupby(level=0) \\\n",
    "                .apply(np.cumsum) \\\n",
    "                .apply(lambda x: len(set(x))))\n",
    "        \n",
    "    counts = results[0].to_frame()\n",
    "    for col, result in zip(cols[1:], results[1:]):\n",
    "        counts[col] = result\n",
    "\n",
    "    counts = counts.reset_index()[[by, 'order_id', *cols]]\n",
    "    return counts\n",
    "\n",
    "def num_stats(df, cols, by):\n",
    "    results = []\n",
    "    for col in cols:\n",
    "        results.append(df.groupby([df.index, df.order_date, df.order_id])[col] \\\n",
    "                .apply(list) \\\n",
    "                .sort_index() \\\n",
    "                .groupby(level=0) \\\n",
    "                .apply(np.cumsum) \\\n",
    "                .apply(lambda x: (np.mean(x), np.std(x), np.min(x), np.max(x), np.sum(x))))\n",
    "        \n",
    "    stats = results[0].to_frame()\n",
    "    for col, result in zip(cols[1:], results[1:]):\n",
    "        stats[col] = result\n",
    "    \n",
    "    stats = stats.reset_index()[[by, 'order_id', *cols]]\n",
    "    for col in cols:\n",
    "        stats[f'{col}_mean_by_{by}'] = stats[col].apply(lambda x: x[0])\n",
    "        stats[f'{col}_std_by_{by}'] = stats[col].apply(lambda x: x[1])\n",
    "        stats[f'{col}_min_by_{by}'] = stats[col].apply(lambda x: x[2])\n",
    "        stats[f'{col}_max_by_{by}'] = stats[col].apply(lambda x: x[3])\n",
    "        stats[f'{col}_sum_by_{by}'] = stats[col].apply(lambda x: x[4])\n",
    "        stats[col] = stats[col].apply(str)\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run(job: PreprocessingJob, context: EventContext) -> FeatureCalcJob:\n",
    "    base_path = context.env['data']['features']\n",
    "    client = get_client(context)\n",
    "    features = {}\n",
    "    try:\n",
    "        path = job.partitioned.get('customer_id')\n",
    "        if path:\n",
    "            logger.info(context, \"Calculating features on customer_id...\")\n",
    "            df = dd.read_parquet(path, \n",
    "                         engine='fastparquet', \n",
    "                         columns=['order_id', 'order_date', 'email', 'ip_addr', 'order_amount'])\n",
    "            df = df.map_partitions(calculate, count_cols=['email', 'ip_addr'], stat_cols=['order_amount'], by='customer_id')\n",
    "            save_path = f'{base_path}/customer_id/'\n",
    "            df.to_parquet(save_path)\n",
    "            features['customer_id'] = save_path \n",
    "            logger.info(context, f\"Saved {save_path}.\")\n",
    "        \n",
    "        path = job.partitioned.get('email')\n",
    "        if path:\n",
    "            logger.info(context, \"Calculating features on email...\")\n",
    "            df = dd.read_parquet(path, \n",
    "                         engine='fastparquet', \n",
    "                         columns=['order_id', 'order_date', 'customer_id', 'ip_addr', 'order_amount'])\n",
    "            df = df.map_partitions(calculate, count_cols=['customer_id'], stat_cols=['order_amount'], by='email')\n",
    "            save_path = f'{base_path}/email/'\n",
    "            df.to_parquet(save_path)\n",
    "            features['email'] = save_path \n",
    "            logger.info(context, f\"Saved {save_path}.\")\n",
    "            \n",
    "        return FeatureCalcJob(\n",
    "            sources=job.partitioned,\n",
    "            features=features\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(context, e)\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
